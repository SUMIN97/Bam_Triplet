{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "#     transforms.Resize((224, 224)), #왜 224?\n",
    "    transforms.ToTensor(), #nparray => tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #0~1값을 -0.5~0.5로 변경\n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "['3DGraphics_Bicycle', '3DGraphics_Bird', '3DGraphics_Cars', '3DGraphics_Cat', '3DGraphics_Dog', '3DGraphics_Flower', '3DGraphics_People', 'Comic_Bicycle', 'Comic_Bird', 'Comic_Cars', 'Comic_Cat', 'Comic_Dog', 'Comic_Flower', 'Comic_People', 'Oil_Bicycle', 'Oil_Bird', 'Oil_Cars', 'Oil_Cat', 'Oil_Dog', 'Oil_Flower', 'Oil_People', 'Pen_Bicycle', 'Pen_Bird', 'Pen_Cars', 'Pen_Cat', 'Pen_Dog', 'Pen_Flower', 'Pen_People', 'Pencil_Bicycle', 'Pencil_Bird', 'Pencil_Cars', 'Pencil_Cat', 'Pencil_Dog', 'Pencil_Flower', 'Pencil_People', 'VectorArt_Bicycle', 'VectorArt_Bird', 'VectorArt_Cars', 'VectorArt_Cat', 'VectorArt_Dog', 'VectorArt_Flower', 'VectorArt_People', 'Watercolor_Bicycle', 'Watercolor_Bird', 'Watercolor_Cars', 'Watercolor_Cat', 'Watercolor_Dog', 'Watercolor_Flower', 'Watercolor_People']\n"
     ]
    }
   ],
   "source": [
    "classes = trainset.classes\n",
    "n_classes = len(classes)\n",
    "\n",
    "\n",
    "print(n_classes)\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[[0.1373, 0.1451, 0.1451,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         [0.1373, 0.1451, 0.1529,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         [0.1373, 0.1451, 0.1529,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         ...,\n",
      "         [0.6627, 0.6627, 0.6627,  ..., 0.7725, 0.7725, 0.7725],\n",
      "         [0.6627, 0.6627, 0.6627,  ..., 0.7725, 0.7725, 0.7804],\n",
      "         [0.6706, 0.6706, 0.6706,  ..., 0.7725, 0.7725, 0.7804]],\n",
      "\n",
      "        [[0.1373, 0.1451, 0.1451,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         [0.1373, 0.1451, 0.1529,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         [0.1373, 0.1451, 0.1529,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         ...,\n",
      "         [0.6627, 0.6627, 0.6627,  ..., 0.7725, 0.7725, 0.7725],\n",
      "         [0.6627, 0.6627, 0.6627,  ..., 0.7725, 0.7725, 0.7804],\n",
      "         [0.6706, 0.6706, 0.6706,  ..., 0.7725, 0.7725, 0.7804]],\n",
      "\n",
      "        [[0.1373, 0.1451, 0.1451,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         [0.1373, 0.1451, 0.1529,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         [0.1373, 0.1451, 0.1529,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         ...,\n",
      "         [0.6627, 0.6627, 0.6627,  ..., 0.7725, 0.7725, 0.7725],\n",
      "         [0.6627, 0.6627, 0.6627,  ..., 0.7725, 0.7725, 0.7804],\n",
      "         [0.6706, 0.6706, 0.6706,  ..., 0.7725, 0.7725, 0.7804]]])\n"
     ]
    }
   ],
   "source": [
    "len(trainset)\n",
    "a = trainset.__getitem__(18)\n",
    "print(a[1], a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
    "              '#9467bd', '#8c564b', '#e377c2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "\n",
    "n_media = 7\n",
    "n_content = 7\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "#     Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
    "\n",
    "    def __init__(self, dataset, kind):\n",
    "        self.dataset = dataset\n",
    "        self.kind = kind\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.label_to_indices = {}\n",
    "        \n",
    "        for m in range(n_media):\n",
    "            for c in range(n_content):\n",
    "                self.label_to_indices[(m,c)] = []\n",
    "                \n",
    "        for i in range(len(dataset)):\n",
    "            e = self.dataset.__getitem__(i)\n",
    "            self.data.append(e[0])\n",
    "            m = int(e[1]/n_media)\n",
    "            c = e[1] % n_media\n",
    "            self.labels.append((m,c))\n",
    "            self.label_to_indices[(m,c)].append(i)\n",
    "            \n",
    "    \n",
    "        if self.kind == 'test':\n",
    "            random_state = np.random.RandomState(29)\n",
    "            triplets = []\n",
    "            keys = list(self.label_to_indices.keys())\n",
    "            anchor_key_index = -1\n",
    "            \n",
    "            for k in range(len(keys)):\n",
    "                if keys[k] == self.labels[i]:\n",
    "                    anchor_key_index = k\n",
    "                    \n",
    "            \n",
    "            for i in range(len(self.data)):\n",
    "                pos_index = random_state.choice(self.label_to_indices[self.labels[i]])\n",
    "                \n",
    "                r = list(range(len(keys)))\n",
    "                r.remove(anchor_key_index)\n",
    "                neg_label = keys[random_state.choice(r)]\n",
    "                neg_index = random_state.choice(self.label_to_indices[neg_label])\n",
    "                \n",
    "                triplets.append([i, pos_index, neg_index])\n",
    "            self.test_triplets = triplets\n",
    "                \n",
    "            \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if self.kind == 'train':\n",
    "            img1, label1 = self.data[index], self.labels[index]\n",
    "            positive_index = index\n",
    "            while positive_index == index:\n",
    "                positive_index = np.random.choice(self.label_to_indices[label1])\n",
    "\n",
    "            negative_m_range = list(range(n_media))\n",
    "            negative_m_range.remove(label1[0])\n",
    "            negative_m = np.random.choice(negative_m_range)\n",
    "\n",
    "            negative_c_range = list(range(n_content))\n",
    "            negative_c_range.remove(label1[1])\n",
    "            negative_c = np.random.choice(negative_c_range)\n",
    "\n",
    "            negative_label = (negative_m, negative_c)\n",
    "            negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
    "\n",
    "            img2 = self.data[positive_index]\n",
    "            img3 = self.data[negative_index]\n",
    "            \n",
    "        elif self.kind == 'test':\n",
    "            img1 = self.data[self.test_triplets[index][0]]\n",
    "            img2 = self.data[self.test_triplets[index][1]]\n",
    "            img3 = self.data[self.test_triplets[index][2]]                \n",
    "            \n",
    "        else:\n",
    "            print('TripletDataset Error')\n",
    "            return\n",
    "        \n",
    "        return (img1, img2, img3), []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageFoler를 통해 불러온 trainset을 DataLoader를 사용해\n",
    "#Batch 형식으로 네트워크에 올리기\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root = './BAM', transform = trans)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root = './test', transform = trans)\n",
    "triplet_train_dataset = TripletDataset(train_dataset, kind = 'train')\n",
    "triplet_test_dataset = TripletDataset(test_dataset, kind = 'test')\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "train_loader = DataLoader(triplet_train_dataset, batch_size = 1, shuffle = True, **kwargs)\n",
    "test_loader = DataLoader(triplet_test_dataset, batch_size = 1, shuffle = True, **kwargs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([[[[-0.9686, -0.9686, -0.9608,  ..., -0.9529, -0.9608, -0.9686],\n",
      "          [-0.8745, -0.8275, -0.9608,  ..., -0.9451, -0.9608, -0.9608],\n",
      "          [-0.7176, -0.6078, -0.9529,  ..., -0.9137, -0.9608, -0.9608],\n",
      "          ...,\n",
      "          [-0.9608, -0.9686, -0.9373,  ..., -0.9529, -0.7725, -0.8667],\n",
      "          [-0.9608, -0.9608, -0.8980,  ..., -0.9529, -0.6157, -0.7647],\n",
      "          [-0.9608, -0.9686, -0.9529,  ..., -0.9686, -0.8824, -0.9216]],\n",
      "\n",
      "         [[-0.2863, -0.2863, -0.2784,  ..., -0.2941, -0.2941, -0.2941],\n",
      "          [-0.2392, -0.2078, -0.2706,  ..., -0.2784, -0.2863, -0.2941],\n",
      "          [-0.1529, -0.0902, -0.2784,  ..., -0.2549, -0.2941, -0.2941],\n",
      "          ...,\n",
      "          [-0.3020, -0.3020, -0.2941,  ..., -0.3098, -0.2157, -0.2549],\n",
      "          [-0.2941, -0.3020, -0.2627,  ..., -0.3098, -0.1216, -0.2078],\n",
      "          [-0.2941, -0.2941, -0.2863,  ..., -0.3098, -0.2706, -0.2941]],\n",
      "\n",
      "         [[-0.3882, -0.3961, -0.3725,  ..., -0.3961, -0.3961, -0.3961],\n",
      "          [-0.3412, -0.3176, -0.3804,  ..., -0.3804, -0.3882, -0.3961],\n",
      "          [-0.2549, -0.1922, -0.3725,  ..., -0.3647, -0.3961, -0.3961],\n",
      "          ...,\n",
      "          [-0.4039, -0.4118, -0.3961,  ..., -0.4118, -0.3176, -0.3647],\n",
      "          [-0.4039, -0.4118, -0.3725,  ..., -0.4196, -0.2392, -0.3255],\n",
      "          [-0.3961, -0.3961, -0.3882,  ..., -0.4118, -0.3804, -0.4039]]]]), tensor([[[[ 0.4275,  0.4275,  0.4196,  ...,  0.4275,  0.4196,  0.4275],\n",
      "          [ 0.4275,  0.4275,  0.4275,  ...,  0.4275,  0.4275,  0.4275],\n",
      "          [ 0.4196,  0.4275,  0.4275,  ...,  0.4196,  0.4196,  0.4275],\n",
      "          ...,\n",
      "          [-0.6549, -0.6549, -0.6549,  ..., -0.6549, -0.6549, -0.6549],\n",
      "          [-0.6549, -0.6549, -0.6549,  ..., -0.6549, -0.6549, -0.6549],\n",
      "          [-0.6549, -0.6549, -0.6549,  ..., -0.6549, -0.6549, -0.6549]],\n",
      "\n",
      "         [[ 0.6627,  0.6627,  0.6549,  ...,  0.6627,  0.6549,  0.6627],\n",
      "          [ 0.6627,  0.6627,  0.6627,  ...,  0.6627,  0.6627,  0.6627],\n",
      "          [ 0.6549,  0.6627,  0.6627,  ...,  0.6549,  0.6549,  0.6627],\n",
      "          ...,\n",
      "          [-0.5843, -0.5843, -0.5843,  ..., -0.5843, -0.5843, -0.5843],\n",
      "          [-0.5843, -0.5843, -0.5843,  ..., -0.5843, -0.5843, -0.5843],\n",
      "          [-0.5843, -0.5843, -0.5843,  ..., -0.5843, -0.5843, -0.5843]],\n",
      "\n",
      "         [[ 0.6627,  0.6627,  0.6549,  ...,  0.6627,  0.6549,  0.6627],\n",
      "          [ 0.6627,  0.6627,  0.6627,  ...,  0.6627,  0.6627,  0.6627],\n",
      "          [ 0.6549,  0.6627,  0.6627,  ...,  0.6549,  0.6549,  0.6627],\n",
      "          ...,\n",
      "          [-0.5294, -0.5294, -0.5294,  ..., -0.5294, -0.5294, -0.5294],\n",
      "          [-0.5294, -0.5294, -0.5294,  ..., -0.5294, -0.5294, -0.5294],\n",
      "          [-0.5294, -0.5294, -0.5294,  ..., -0.5294, -0.5294, -0.5294]]]]), tensor([[[[-0.8510, -0.8588, -0.8510,  ..., -0.5529, -0.6000, -0.5529],\n",
      "          [-0.8510, -0.8510, -0.8510,  ..., -0.5922, -0.6235, -0.5686],\n",
      "          [-0.8667, -0.8667, -0.8745,  ..., -0.6392, -0.5765, -0.6000],\n",
      "          ...,\n",
      "          [-0.0824, -0.0902, -0.0980,  ..., -0.1059, -0.1216, -0.1216],\n",
      "          [-0.1137, -0.1137, -0.1137,  ..., -0.1059, -0.1294, -0.1137],\n",
      "          [-0.1294, -0.0902, -0.1059,  ..., -0.1216, -0.1216, -0.0980]],\n",
      "\n",
      "         [[-0.8745, -0.8824, -0.8745,  ..., -0.4353, -0.4824, -0.4275],\n",
      "          [-0.8667, -0.8667, -0.8667,  ..., -0.4824, -0.5137, -0.4510],\n",
      "          [-0.8824, -0.8902, -0.8980,  ..., -0.5294, -0.4667, -0.4824],\n",
      "          ...,\n",
      "          [ 0.0118, -0.0039, -0.0039,  ..., -0.0196, -0.0431, -0.0431],\n",
      "          [-0.0275, -0.0196, -0.0275,  ..., -0.0196, -0.0510, -0.0353],\n",
      "          [-0.0353,  0.0118, -0.0118,  ..., -0.0353, -0.0431, -0.0196]],\n",
      "\n",
      "         [[-0.7961, -0.8118, -0.7961,  ..., -0.8588, -0.9294, -0.8902],\n",
      "          [-0.8196, -0.8196, -0.8196,  ..., -0.8745, -0.9137, -0.8745],\n",
      "          [-0.8275, -0.8275, -0.8353,  ..., -0.9216, -0.8588, -0.8980],\n",
      "          ...,\n",
      "          [-0.8196, -0.7725, -0.7961,  ..., -0.7882, -0.8039, -0.8039],\n",
      "          [-0.7882, -0.7961, -0.8039,  ..., -0.7961, -0.8118, -0.7961],\n",
      "          [-0.7961, -0.8118, -0.8118,  ..., -0.8118, -0.8039, -0.7804]]]])], []]\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "print(dataiter.next())\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "class StyleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StyleNet, self).__init__()\n",
    "        self.covnet = nn.Sequential(*list(vgg16(pretrained = True).features)[:29])  #vgg block5-1 conv 까지\n",
    "        \n",
    "        self.fc = nn.Linear(512 * 512, 2048)\n",
    "        \n",
    "    def gram_matrix(self, x):\n",
    "        b, c, h, w = x.size()  # a=batch size(=1)\n",
    "        # b=number of feature maps\n",
    "        # (c,d)=dimensions of a f. map (N=c*d)\n",
    "\n",
    "        features = x.view(b * c, h * w)  # resise F_XL into \\hat F_XL\n",
    "\n",
    "        G = torch.mm(features, features.t())  # compute the gram product\n",
    "        \n",
    "        return G #512 * 512\n",
    "\n",
    "#         # we 'normalize' the values of the gram matrix\n",
    "#         # by dividing by the number of element in each feature maps.\n",
    "#         return G.div(a * b * c * d)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = self.covnet(x)      \n",
    "        output = self.gram_matrix(output)\n",
    "        output = torch.flatten(output)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "class ContentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContentNet, self).__init__()\n",
    "        self.convnet = nn.Sequential(*list(vgg16(pretrained = True).features)) \n",
    "        self.avg_pool = nn.AvgPool2d(7)\n",
    "        self.fc1 = nn.Linear(512, 2048)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.convnet(x)\n",
    "        output = self.avg_pool(output)\n",
    "        output = torch.flatten(output)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "    \n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, style, content):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.style = style\n",
    "        self.content = content\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x1, x2, x3):\n",
    "        output1 = torch.cat([self.style(x1), self.content(x1)], dim = 0)\n",
    "        output2 = torch.cat([self.style(x1), self.content(x2)], dim = 0)\n",
    "        output3 = torch.cat([self.style(x1), self.content(x3)], dim = 0)\n",
    "        \n",
    "        return output1, output2, output3\n",
    "    \n",
    "    def get_style(self, x):\n",
    "        return self.style(x)\n",
    "    def get_content(self, x):\n",
    "        return self.content(x)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplet loss\n",
    "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, anchor, positive, negative, size_average = True):\n",
    "        distance_positive = (anchor - positive).pow(2).sum()  # .pow(.5)\n",
    "        distance_negative = (anchor - negative).pow(2).sum()  # .pow(.5)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 1\n",
    "style_net = StyleNet()\n",
    "content_net = ContentNet()\n",
    "model = TripletNet(style_net, content_net)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = TripletLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "n_epochs = 20\n",
    "# for epoch in range(100):\n",
    "#     running_loss = 0.0\n",
    "#     for i, data im enumerate(train_loader, 0):\n",
    "#         inputs, labels = data\n",
    "#         inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(train_loader, model, loss_fn, optimizer, cuda):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        target = target if len(target) > 0 else None\n",
    "        if not type(data) in (tuple, list):\n",
    "            data = (data,)\n",
    "        if cuda:\n",
    "            data = tuple(d.cuda() for d in data)\n",
    "            if target is not None:\n",
    "                target = target.cuda()\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*data)\n",
    "\n",
    "        if type(outputs) not in (tuple, list):\n",
    "            outputs = (outputs,)\n",
    "\n",
    "        loss_inputs = outputs\n",
    "        if target is not None:\n",
    "            target = (target,)\n",
    "            loss_inputs += target\n",
    "\n",
    "        loss_outputs = loss_fn(*loss_inputs)\n",
    "        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "        losses.append(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    total_loss /= (batch_idx + 1)\n",
    "    return total_loss\n",
    "    \n",
    "#     for batch_idx, data in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         if cuda:\n",
    "#             data = tuple(d.cuda() for d in data)\n",
    "        \n",
    "#         outputs = model(*data)\n",
    "#         loss = loss_fn(outputs[0], outputs[1], outputs[2])\n",
    "#         total_loss += loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#     return total_loss/(len(train_loader)/batch_size)\n",
    "        \n",
    "        \n",
    "# def test_epoch(test_loader, model, loss_fn, optimizer, cuda):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     for batch_idx, data in enumerate(test_loader):\n",
    "#         if cuda:\n",
    "#             data = tuple(d.cuda() for d in data)\n",
    "\n",
    "#         outputs = model(*data)\n",
    "#         loss = loss_fn(outputs[0], outputs[1], outputs[2])\n",
    "#         total_loss += loss\n",
    "\n",
    "    \n",
    "def test_epoch(val_loader, model, loss_fn, cuda):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(val_loader)):\n",
    "            target = target if len(target) > 0 else None\n",
    "            if not type(data) in (tuple, list):\n",
    "                data = (data,)\n",
    "            if cuda:\n",
    "                data = tuple(d.cuda() for d in data)\n",
    "                if target is not None:\n",
    "                    target = target.cuda()\n",
    "\n",
    "            outputs = model(*data)\n",
    "\n",
    "            if type(outputs) not in (tuple, list):\n",
    "                outputs = (outputs,)\n",
    "            loss_inputs = outputs\n",
    "            if target is not None:\n",
    "                target = (target,)\n",
    "                loss_inputs += target\n",
    "\n",
    "            loss_outputs = loss_fn(*loss_inputs)\n",
    "            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss       \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "def fit(train_loader, val_loader, model, loss_fn, optimizer,  n_epochs, cuda):\n",
    "    \"\"\"\n",
    "    Loaders, model, loss function and metrics should work together for a given task,\n",
    "    i.e. The model should be able to process data output of loaders,\n",
    "    loss function should process target output of loaders and outputs from the model\n",
    "\n",
    "    Examples: Classification: batch loader, classification model, NLL loss, accuracy metric\n",
    "    Siamese network: Siamese loader, siamese model, contrastive loss\n",
    "    Online triplet learning: batch loader, embedding model, online triplet loss\n",
    "    \"\"\"\n",
    "\n",
    "    # Train stage\n",
    "    for epoch in range(n_epochs):       \n",
    "        train_loss = train_epoch(train_loader, model, loss_fn, optimizer, cuda)\n",
    "\n",
    "        message = 'Epoch: {}/{}. Train set: Average loss: {:.4f}'.format(epoch + 1, n_epochs, train_loss)\n",
    "\n",
    "        val_loss = test_epoch(val_loader, model, loss_fn, cuda)\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        message += '\\nEpoch: {}/{}. Validation set: Average loss: {:.4f}'.format(epoch + 1, n_epochs,\n",
    "                                                                                 val_loss)\n",
    "\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2303 [01:19<25:23:32, 39.73s/it]"
     ]
    }
   ],
   "source": [
    "fit(train_loader, test_loader, model, loss_fn, optimizer, n_epochs, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(vgg16.features)[:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "tqdm(enumerate(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
